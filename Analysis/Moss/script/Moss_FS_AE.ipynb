{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the data,in this notebook we are using the Moss data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 11:41:21.225486: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-16 11:41:21.227908: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-16 11:41:21.231401: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-16 11:41:21.241001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737045681.257566 2002107 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737045681.262490 2002107 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-16 11:41:21.280564: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../Code')\n",
    "import loadData \n",
    "import RunML\n",
    "import RunML_continue\n",
    "import FS\n",
    "import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data and data preprocess\n",
    "After reading the data, convert the abundance matrix into relative abundance matrix; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beijerinckiaceae</th>\n",
       "      <th>Mycobacteriaceae</th>\n",
       "      <th>Ktedonobacteraceae</th>\n",
       "      <th>Bryum argenteum var. argenteum</th>\n",
       "      <th>Burkholderiaceae</th>\n",
       "      <th>Micromonosporaceae</th>\n",
       "      <th>Opitutaceae</th>\n",
       "      <th>WD2101 soil group</th>\n",
       "      <th>Xanthobacteraceae</th>\n",
       "      <th>Chitinophagaceae</th>\n",
       "      <th>...</th>\n",
       "      <th>Marinifilaceae</th>\n",
       "      <th>Aerococcaceae</th>\n",
       "      <th>Acetobacterales Incertae Sedis</th>\n",
       "      <th>Bacteroidaceae</th>\n",
       "      <th>Hydrogenophilaceae</th>\n",
       "      <th>Arachis hypogaea var. vulgaris</th>\n",
       "      <th>Demequinaceae</th>\n",
       "      <th>Pseudohongiellaceae</th>\n",
       "      <th>Bacteroidetes vadinHA17</th>\n",
       "      <th>Thermoanaerobacteraceae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sp1</th>\n",
       "      <td>57.894737</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp2</th>\n",
       "      <td>1.448965</td>\n",
       "      <td>0.631692</td>\n",
       "      <td>0.039258</td>\n",
       "      <td>10.413990</td>\n",
       "      <td>6.381156</td>\n",
       "      <td>4.043540</td>\n",
       "      <td>4.025696</td>\n",
       "      <td>3.540328</td>\n",
       "      <td>3.404711</td>\n",
       "      <td>3.222698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp4</th>\n",
       "      <td>1.247068</td>\n",
       "      <td>0.856460</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.564467</td>\n",
       "      <td>1.226043</td>\n",
       "      <td>1.406409</td>\n",
       "      <td>3.713540</td>\n",
       "      <td>6.305050</td>\n",
       "      <td>6.754304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp5</th>\n",
       "      <td>0.524455</td>\n",
       "      <td>1.700505</td>\n",
       "      <td>0.190711</td>\n",
       "      <td>0.131114</td>\n",
       "      <td>8.470738</td>\n",
       "      <td>2.789145</td>\n",
       "      <td>3.198379</td>\n",
       "      <td>5.602130</td>\n",
       "      <td>3.929437</td>\n",
       "      <td>3.579801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp6</th>\n",
       "      <td>5.468805</td>\n",
       "      <td>80.751917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.992825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274319</td>\n",
       "      <td>0.235633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp7</th>\n",
       "      <td>2.525957</td>\n",
       "      <td>1.713743</td>\n",
       "      <td>0.005582</td>\n",
       "      <td>0.018142</td>\n",
       "      <td>4.873283</td>\n",
       "      <td>0.117227</td>\n",
       "      <td>1.646757</td>\n",
       "      <td>6.127889</td>\n",
       "      <td>2.756224</td>\n",
       "      <td>1.773752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp8</th>\n",
       "      <td>2.184587</td>\n",
       "      <td>1.202563</td>\n",
       "      <td>1.198402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.023136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.890479</td>\n",
       "      <td>4.277630</td>\n",
       "      <td>5.629993</td>\n",
       "      <td>3.649301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp9</th>\n",
       "      <td>1.280438</td>\n",
       "      <td>0.458262</td>\n",
       "      <td>0.705364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.149160</td>\n",
       "      <td>4.834217</td>\n",
       "      <td>2.920298</td>\n",
       "      <td>4.506245</td>\n",
       "      <td>3.149429</td>\n",
       "      <td>3.037110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp10</th>\n",
       "      <td>7.142857</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.844156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp11</th>\n",
       "      <td>0.997030</td>\n",
       "      <td>0.735948</td>\n",
       "      <td>0.068108</td>\n",
       "      <td>9.724351</td>\n",
       "      <td>3.942713</td>\n",
       "      <td>1.772707</td>\n",
       "      <td>2.166222</td>\n",
       "      <td>2.079195</td>\n",
       "      <td>4.222714</td>\n",
       "      <td>5.223528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp12</th>\n",
       "      <td>0.683286</td>\n",
       "      <td>1.895930</td>\n",
       "      <td>0.198979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.525304</td>\n",
       "      <td>6.284727</td>\n",
       "      <td>0.551885</td>\n",
       "      <td>2.800721</td>\n",
       "      <td>5.984382</td>\n",
       "      <td>2.402763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp13</th>\n",
       "      <td>4.018762</td>\n",
       "      <td>2.288878</td>\n",
       "      <td>0.075826</td>\n",
       "      <td>10.765487</td>\n",
       "      <td>4.905747</td>\n",
       "      <td>0.617186</td>\n",
       "      <td>0.357968</td>\n",
       "      <td>2.331200</td>\n",
       "      <td>1.144439</td>\n",
       "      <td>1.518278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp14</th>\n",
       "      <td>4.194349</td>\n",
       "      <td>4.617800</td>\n",
       "      <td>0.040155</td>\n",
       "      <td>0.135066</td>\n",
       "      <td>10.947653</td>\n",
       "      <td>0.032854</td>\n",
       "      <td>0.178871</td>\n",
       "      <td>1.062276</td>\n",
       "      <td>0.741038</td>\n",
       "      <td>0.996569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054757</td>\n",
       "      <td>0.032854</td>\n",
       "      <td>0.032854</td>\n",
       "      <td>0.032854</td>\n",
       "      <td>0.032854</td>\n",
       "      <td>0.029203</td>\n",
       "      <td>0.029203</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp15</th>\n",
       "      <td>1.897887</td>\n",
       "      <td>2.090615</td>\n",
       "      <td>10.224414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.952569</td>\n",
       "      <td>0.133930</td>\n",
       "      <td>1.215170</td>\n",
       "      <td>7.830007</td>\n",
       "      <td>4.200830</td>\n",
       "      <td>0.852579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp16</th>\n",
       "      <td>20.714286</td>\n",
       "      <td>25.357143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp17</th>\n",
       "      <td>24.786325</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.658120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.350427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Beijerinckiaceae  Mycobacteriaceae  Ktedonobacteraceae  \\\n",
       "Sp1          57.894737         31.578947           10.526316   \n",
       "Sp2           1.448965          0.631692            0.039258   \n",
       "Sp3           0.000000          0.000000            0.000000   \n",
       "Sp4           1.247068          0.856460            0.017705   \n",
       "Sp5           0.524455          1.700505            0.190711   \n",
       "Sp6           5.468805         80.751917            0.000000   \n",
       "Sp7           2.525957          1.713743            0.005582   \n",
       "Sp8           2.184587          1.202563            1.198402   \n",
       "Sp9           1.280438          0.458262            0.705364   \n",
       "Sp10          7.142857          7.142857            4.545455   \n",
       "Sp11          0.997030          0.735948            0.068108   \n",
       "Sp12          0.683286          1.895930            0.198979   \n",
       "Sp13          4.018762          2.288878            0.075826   \n",
       "Sp14          4.194349          4.617800            0.040155   \n",
       "Sp15          1.897887          2.090615           10.224414   \n",
       "Sp16         20.714286         25.357143            0.000000   \n",
       "Sp17         24.786325         15.384615            0.000000   \n",
       "\n",
       "      Bryum argenteum var. argenteum  Burkholderiaceae  Micromonosporaceae  \\\n",
       "Sp1                         0.000000          0.000000            0.000000   \n",
       "Sp2                        10.413990          6.381156            4.043540   \n",
       "Sp3                         0.000000          0.000000            0.000000   \n",
       "Sp4                         0.000000          4.564467            1.226043   \n",
       "Sp5                         0.131114          8.470738            2.789145   \n",
       "Sp6                         0.000000          5.992825            0.000000   \n",
       "Sp7                         0.018142          4.873283            0.117227   \n",
       "Sp8                         0.000000         17.023136            0.000000   \n",
       "Sp9                         0.000000         10.149160            4.834217   \n",
       "Sp10                        0.000000          0.000000            0.000000   \n",
       "Sp11                        9.724351          3.942713            1.772707   \n",
       "Sp12                        0.000000          3.525304            6.284727   \n",
       "Sp13                       10.765487          4.905747            0.617186   \n",
       "Sp14                        0.135066         10.947653            0.032854   \n",
       "Sp15                        0.000000          3.952569            0.133930   \n",
       "Sp16                        0.000000          5.000000            0.000000   \n",
       "Sp17                        0.000000         19.658120            0.000000   \n",
       "\n",
       "      Opitutaceae  WD2101 soil group  Xanthobacteraceae  Chitinophagaceae  \\\n",
       "Sp1      0.000000           0.000000           0.000000          0.000000   \n",
       "Sp2      4.025696           3.540328           3.404711          3.222698   \n",
       "Sp3      0.000000           0.000000           0.000000          0.000000   \n",
       "Sp4      1.406409           3.713540           6.305050          6.754304   \n",
       "Sp5      3.198379           5.602130           3.929437          3.579801   \n",
       "Sp6      0.014068           0.000000           0.274319          0.235633   \n",
       "Sp7      1.646757           6.127889           2.756224          1.773752   \n",
       "Sp8      0.890479           4.277630           5.629993          3.649301   \n",
       "Sp9      2.920298           4.506245           3.149429          3.037110   \n",
       "Sp10     0.000000           0.000000           0.000000          5.844156   \n",
       "Sp11     2.166222           2.079195           4.222714          5.223528   \n",
       "Sp12     0.551885           2.800721           5.984382          2.402763   \n",
       "Sp13     0.357968           2.331200           1.144439          1.518278   \n",
       "Sp14     0.178871           1.062276           0.741038          0.996569   \n",
       "Sp15     1.215170           7.830007           4.200830          0.852579   \n",
       "Sp16     0.000000           0.000000           0.000000          0.000000   \n",
       "Sp17     0.000000           0.000000           0.000000          2.350427   \n",
       "\n",
       "      ...  Marinifilaceae  Aerococcaceae  Acetobacterales Incertae Sedis  \\\n",
       "Sp1   ...        0.000000       0.000000                        0.000000   \n",
       "Sp2   ...        0.000000       0.000000                        0.000000   \n",
       "Sp3   ...        0.000000       0.000000                        0.000000   \n",
       "Sp4   ...        0.000000       0.000000                        0.000000   \n",
       "Sp5   ...        0.000000       0.000000                        0.000000   \n",
       "Sp6   ...        0.000000       0.000000                        0.000000   \n",
       "Sp7   ...        0.000000       0.000000                        0.000000   \n",
       "Sp8   ...        0.000000       0.000000                        0.000000   \n",
       "Sp9   ...        0.000000       0.000000                        0.000000   \n",
       "Sp10  ...        0.000000       0.000000                        0.000000   \n",
       "Sp11  ...        0.000000       0.000000                        0.000000   \n",
       "Sp12  ...        0.000000       0.000000                        0.000000   \n",
       "Sp13  ...        0.000000       0.000000                        0.000000   \n",
       "Sp14  ...        0.054757       0.032854                        0.032854   \n",
       "Sp15  ...        0.000000       0.000000                        0.000000   \n",
       "Sp16  ...        0.000000       0.000000                        0.000000   \n",
       "Sp17  ...        0.000000       0.000000                        0.000000   \n",
       "\n",
       "      Bacteroidaceae  Hydrogenophilaceae  Arachis hypogaea var. vulgaris  \\\n",
       "Sp1         0.000000            0.000000                        0.000000   \n",
       "Sp2         0.000000            0.000000                        0.000000   \n",
       "Sp3         0.000000            0.000000                        0.000000   \n",
       "Sp4         0.000000            0.000000                        0.000000   \n",
       "Sp5         0.000000            0.000000                        0.000000   \n",
       "Sp6         0.000000            0.000000                        0.000000   \n",
       "Sp7         0.000000            0.000000                        0.000000   \n",
       "Sp8         0.000000            0.000000                        0.000000   \n",
       "Sp9         0.000000            0.000000                        0.000000   \n",
       "Sp10        0.000000            0.000000                        0.000000   \n",
       "Sp11        0.000000            0.000000                        0.000000   \n",
       "Sp12        0.000000            0.000000                        0.000000   \n",
       "Sp13        0.000000            0.000000                        0.000000   \n",
       "Sp14        0.032854            0.032854                        0.029203   \n",
       "Sp15        0.000000            0.000000                        0.000000   \n",
       "Sp16        0.000000            0.000000                        0.000000   \n",
       "Sp17        0.000000            0.000000                        0.000000   \n",
       "\n",
       "      Demequinaceae  Pseudohongiellaceae  Bacteroidetes vadinHA17  \\\n",
       "Sp1        0.000000             0.000000                 0.000000   \n",
       "Sp2        0.000000             0.000000                 0.000000   \n",
       "Sp3        0.000000             0.000000                 0.000000   \n",
       "Sp4        0.000000             0.000000                 0.000000   \n",
       "Sp5        0.000000             0.000000                 0.000000   \n",
       "Sp6        0.000000             0.000000                 0.000000   \n",
       "Sp7        0.000000             0.000000                 0.000000   \n",
       "Sp8        0.000000             0.000000                 0.000000   \n",
       "Sp9        0.000000             0.000000                 0.000000   \n",
       "Sp10       0.000000             0.000000                 0.000000   \n",
       "Sp11       0.000000             0.000000                 0.000000   \n",
       "Sp12       0.000000             0.000000                 0.000000   \n",
       "Sp13       0.000000             0.000000                 0.000000   \n",
       "Sp14       0.029203             0.025553                 0.025553   \n",
       "Sp15       0.000000             0.000000                 0.000000   \n",
       "Sp16       0.000000             0.000000                 0.000000   \n",
       "Sp17       0.000000             0.000000                 0.000000   \n",
       "\n",
       "      Thermoanaerobacteraceae  \n",
       "Sp1                  0.000000  \n",
       "Sp2                  0.000000  \n",
       "Sp3                  0.000000  \n",
       "Sp4                  0.000000  \n",
       "Sp5                  0.000000  \n",
       "Sp6                  0.000000  \n",
       "Sp7                  0.000000  \n",
       "Sp8                  0.000000  \n",
       "Sp9                  0.000000  \n",
       "Sp10                 0.000000  \n",
       "Sp11                 0.000000  \n",
       "Sp12                 0.000000  \n",
       "Sp13                 0.000000  \n",
       "Sp14                 0.000000  \n",
       "Sp15                 0.016333  \n",
       "Sp16                 0.000000  \n",
       "Sp17                 0.000000  \n",
       "\n",
       "[17 rows x 328 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../data/relative_abundance_df.csv',index_col = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      NO.                           Moss name classification(30)  Week 4  \\\n",
      "0    sp.1             Brachythecium Rutabulum               Good      33   \n",
      "1    sp.2                  Platygyrium Repens                Bad       0   \n",
      "2    sp.3            Bryoandersonia illecebra               Good      10   \n",
      "3    sp.4                Aulacomnium Palustre                Bad       0   \n",
      "4    sp.5                   Entodon seductrix               Good       0   \n",
      "5    sp.6                    Hedwigia ciliata                Bad       0   \n",
      "6    sp.7                  Leucobryum glaucum                Bad       0   \n",
      "7    sp.8                   Sphagnum palustre                Bad       0   \n",
      "8    sp.9                      Bryum argentum                Bad       0   \n",
      "9   sp.10                Ceretodon purpureous                Bad       0   \n",
      "10  sp.11                 Atrichum angustatum               Good      55   \n",
      "11  sp.12                 Anomodon attenuates               Good       9   \n",
      "12  sp.13                  Bryum Caetspitcium                Bad       5   \n",
      "13  sp.14                          Sheet moss               Good       0   \n",
      "14  sp.15                        Haircap moss                Bad       7   \n",
      "15  sp.16                        Cushion moss               Good      20   \n",
      "16  sp.17  Claopodium rostratum (campus moss)               Good      41   \n",
      "\n",
      "    Week 5  Week 6  Week 7  Week 8  Week 10  Week 12  \n",
      "0       45      47      47      74       78       78  \n",
      "1        0       0       2       2        2        2  \n",
      "2       11      18      30      31       36       46  \n",
      "3        1       3       4       9        9        9  \n",
      "4        1       9      13      19       30       31  \n",
      "5        0       0       0       0        0        0  \n",
      "6        0       1       1       1        1        1  \n",
      "7        3       5       9      10       10       12  \n",
      "8        0       0       0       0        1        0  \n",
      "9        0       0       0       0        0        0  \n",
      "10      55      57      57      57       65       66  \n",
      "11      10      10       0       2       20       32  \n",
      "12       6      10      12      25       25       27  \n",
      "13       2       2      16      22       45       53  \n",
      "14       7      10      13      16       21       23  \n",
      "15      23      32      33      39       42       45  \n",
      "16      58      88      98      99      100      100  \n",
      "['Good' 'Bad' 'Good' 'Bad' 'Good' 'Bad' 'Bad' 'Bad' 'Bad' 'Bad' 'Good'\n",
      " 'Good' 'Bad' 'Good' 'Bad' 'Good' 'Good']\n",
      "Bad     9\n",
      "Good    8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# target variable\n",
    "y_data = pd.read_excel('../data/rawdata/Moss-classification.xlsx') \n",
    "print(y_data)\n",
    "y = y_data.iloc[:,2].values\n",
    "print(y)\n",
    "print(pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Beijerinckiaceae', 'Mycobacteriaceae', 'Ktedonobacteraceae',\n",
       "       'Bryum argenteum var. argenteum', 'Burkholderiaceae',\n",
       "       'Micromonosporaceae', 'Opitutaceae', 'WD2101 soil group',\n",
       "       'Xanthobacteraceae', 'Chitinophagaceae',\n",
       "       ...\n",
       "       'Marinifilaceae', 'Aerococcaceae', 'Acetobacterales Incertae Sedis',\n",
       "       'Bacteroidaceae', 'Hydrogenophilaceae',\n",
       "       'Arachis hypogaea var. vulgaris', 'Demequinaceae',\n",
       "       'Pseudohongiellaceae', 'Bacteroidetes vadinHA17',\n",
       "       'Thermoanaerobacteraceae'],\n",
       "      dtype='object', length=328)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASVs = df.columns\n",
    "ASVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Kruskal-Wallis H-test\n",
    "The default p value of the function is 10%, the resulted index is ranked by its H statistics descendingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "select_result = FS.SelectMicro_fun(df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['selected_data', 'selected_columnames', 'selected_indices', 'relative_abundance_data', 'H_score'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_result.keys()\n",
    "# abundance matrix--> relative abundance matrix (relative by sample, and delete that below 1%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=select_result['relative_abundance_data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 11:42:32.448048: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent dimension: 100, activation:tanh, opt:adam,MAE:0.5693972706794739\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, y_train, y_test = RunML_continue.split_and_scale_data(data,y)\n",
    "AE_train, AE_test = RunML_continue.run_AE(data_train,data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_AE = pd.concat([AE_train, AE_test], axis=0).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_AE = pd.DataFrame(data_AE)\n",
    "df_AE['Y'] =y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Prepare 4 datasets: full dataset, our selected dataset, Lasso selected  dataset(based on the target variable), randomly selected data (selected the same numer of variables as in our method)\n",
    "\n",
    "Use random forest and SVM as classifier, and will build both models for each response variable.\n",
    "\n",
    "For Lasso, the dataset will be determined by the response variable, so the lasso subset is different for the models for different response variables.\n",
    "\n",
    "For random selection, the  process will repeat iter=30 times to  find the mean accuracy and AUC\n",
    "\n",
    "SMOTE  is used (the data is not balanced, as we can see the performance is really bad especially for SVM model when not using SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter =30\n",
    "cls = [\"RF\",\"SVM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetLabel=y\n",
    "print(selectedOTU_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lasso,xlabel_lasso = RunML_continue.LassoFeatureSelection(data,targetLabel)\n",
    "print(xlabel_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lasso_ft,xlabel_lasso_ft  = RunML_continue.LassoFS_CV(data,targetLabel)\n",
    "print(xlabel_lasso_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = {\"AllFeatures\":data, \n",
    "               \"SelectMicro\": X_FS,\n",
    "               \"Lasso\":X_lasso,\n",
    "               \"Lasso_finetune\":X_lasso_ft,\n",
    "               \"Random\":data\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(data))\n",
    "print(np.shape(X_FS))\n",
    "print(np.shape(X_lasso))\n",
    "print(np.shape(X_lasso_ft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  function will print out the accuracy and AUC for each dataset using each classifier, and also will return the y_actual, y_predict, y_predprob for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the features selected by SelectMicro and Lasso\n",
    "ASVs_selected_lasso = ASVs[xlabel_lasso]\n",
    "# Convert arrays to sets for easier operations\n",
    "set_FS = set(ASVs_selected)\n",
    "set_Lasso = set(ASVs_selected_lasso)\n",
    "# Items in both arrays (intersection)\n",
    "intersection = set_FS & set_Lasso\n",
    "# Items in array A but not in array B (difference)\n",
    "only_in_a = set_FS - set_Lasso\n",
    "# Items in array B but not in array A (difference)\n",
    "only_in_b = set_Lasso - set_FS\n",
    "# Print results\n",
    "print(\"Items in both selection:\", intersection)\n",
    "print(\"Items in array FS but not in Lasso:\", only_in_a)\n",
    "print(\"Items in Lasso but not in FS:\", only_in_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS.OTUviolin(X_FS,y,ASVs_selected)\n",
    "FS.OTUviolin(X_lasso,y,ASVs_selected_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASVs_selected_lasso = ASVs[xlabel_lasso]\n",
    "ASVs_selected_lasso_ft = ASVs[xlabel_lasso_ft]\n",
    "\n",
    "df_lasso = pd.DataFrame(X_lasso, columns=ASVs_selected_lasso)\n",
    "df_lasso2=df_lasso[list(only_in_b)]\n",
    "df_lasso2['Y'] =y\n",
    "\n",
    "print(df_lasso2.sort_values(by='Y'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lasso_FS1 = data[:,np.intersect1d(selectedOTU_index, xlabel_lasso)]\n",
    "X_lasso_FS2 = data[:,np.intersect1d(selectedOTU_index, xlabel_lasso_ft)]\n",
    "print(np.shape(X_lasso_FS1))\n",
    "print(np.shape(X_lasso_FS2))\n",
    "data_subset2 = {\n",
    "               \"intersection\":X_lasso_FS1,\n",
    "               \"intersection_ft\": X_lasso_FS2\n",
    "              }\n",
    "\n",
    "dict_cm2 = RunML_continue.runClassifier_FScompare(data_subsets= data_subset2,y= targetLabel,N=iter,classifiers=cls)\n",
    "print(metric.metric_sum(dict_cm2))\n",
    "\n",
    "X_FS_lasso,xlabel_FS_lasso = RunML_continue.LassoFeatureSelection(X_FS,targetLabel)\n",
    "print(xlabel_FS_lasso)\n",
    "X_FS_lasso_ft,xlabel_FS_lasso_ft  = RunML_continue.LassoFS_CV(X_FS,targetLabel)\n",
    "print(xlabel_FS_lasso_ft)\n",
    "data_subset3 = {\n",
    "               \"FS_Lasso\":X_FS_lasso,\n",
    "               \"FS_Lassoft\": X_FS_lasso_ft\n",
    "              }\n",
    "dict_cm3 = RunML_continue.runClassifier_FScompare(data_subsets= data_subset3,y= targetLabel,N=iter,classifiers=cls)\n",
    "print(metric.metric_sum(dict_cm3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cm = RunML_continue.runClassifier_FScompare(data_subsets= data_subset,y= targetLabel,N=iter,classifiers=cls,SMOTE=False)\n",
    "print(metric.metric_sum(dict_cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASVs_selected_RF_lasso = ASVs_selected[xlabel_FS_lasso_ft]\n",
    "FS.OTUviolin(X_FS_lasso_ft,y,ASVs_selected_RF_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name, classifiers in dict_cm.items():\n",
    "        for classifier_name, labels in classifiers.items():\n",
    "            actual_labels = labels[0]\n",
    "            predicted_labels = labels[1]\n",
    "            metric.plot_confusion_matrices(actual_labels, predicted_labels,f\"{dataset_name} - {classifier_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from itertools import product\n",
    "from cliffs_delta import compute as cliffs_delta_compute\n",
    "# Function to calculate Cliff's Delta for each feature\n",
    "def cliffs_delta_per_feature(X, y):\n",
    "    \"\"\"\n",
    "    Calculate Cliff's Delta for each feature.\n",
    "    \n",
    "    Parameters:\n",
    "    X (ndarray): 2D array of shape (n_samples, n_features) representing feature data.\n",
    "    y (ndarray): 1D array of shape (n_samples,) representing group labels (0 or 1).\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary where keys are feature indices and values are the corresponding Cliff's Delta for each feature.\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    delta_values = {}\n",
    "    \n",
    "    # Separate the data into two groups based on y\n",
    "    group_0 = X[y == 0]  # Group 0\n",
    "    group_1 = X[y == 1]  # Group 1\n",
    "    \n",
    "    # Calculate Cliff's Delta for each feature\n",
    "    for feature_idx in range(n_features):\n",
    "        feature_0 = group_0[:, feature_idx]  # Get feature column for group 0\n",
    "        feature_1 = group_1[:, feature_idx]  # Get feature column for group 1\n",
    "        \n",
    "        # Calculate Cliff's Delta for the current feature\n",
    "        delta = cliffs_delta_compute(feature_0, feature_1)\n",
    "        delta_values[feature_idx] = delta\n",
    "    \n",
    "    return delta_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare the first 15 index by their present ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "FS.plotPresenseRatio(X_FS,targetLabel,ASVs_selected,posLabel=\"Good\",posText=\"Good\",negText=\"Bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FS.plotPresenseRatio(X_lasso,targetLabel,ASVs_selected_lasso,posLabel=\"Good\",posText=\"Good\",negText=\"Bad\")\n",
    "\n",
    "FS.plotPresenseRatio(X_lasso_ft,targetLabel,ASVs_selected_lasso_ft,posLabel=\"Good\",posText=\"Good\",negText=\"Bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results = []\n",
    "for dataset_name, classifiers in dict_cm.items():\n",
    "        for classifier_name, labels in classifiers.items():\n",
    "            actual_labels = labels[0]\n",
    "            predicted_labels = labels[1]\n",
    "            print(metric_tb(actual_labels,predicted_labels))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name, classifiers in dict_cm.items():\n",
    "        for classifier_name, labels in classifiers.items():\n",
    "            actual_labels = labels[0]\n",
    "            predicted_labels = labels[1]\n",
    "            print(pd.DataFrame([metric_tb(actual_labels,predicted_labels)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lasso=pd.DataFrame(X_lasso)\n",
    "df_lasso.columns = ASVs_selected_lasso\n",
    "df_lasso.index = y\n",
    "\n",
    "# Sort DataFrame by index\n",
    "df_sorted = df_lasso.sort_index()\n",
    "\n",
    "#print(\"\\nSorted DataFrame by index:\")\n",
    "#print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[xlabel_lasso]# check it's H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Gini Impurity\n",
    "Gini Impurity is the probability of incorrectly classifying a randomly chosen element in the dataset if it were randomly labeled according to the class distribution in the dataset. It’s calculated as:\n",
    "\n",
    "$G = 1- \\sum_{i=1}^C p_i^2$\n",
    "\n",
    "where C is the number of classes. (which means it can be used to measure for multiple level classification)\n",
    "\n",
    "Here I will use the negative Gini Impurity to measure each OTU, if NG is large (1) which means the OTU only exist in one class, if NG value is small($1/c$) which means the OTU is evenly distributed among  the classes.\n",
    "\n",
    "$NG = \\sum_{i=1}^C p_i^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NG for selected OTU\n",
    "NG_selected = metric.Neg_GINI(X_FS,y)\n",
    "print(NG_selected.shape)\n",
    "# NG for Not selected OTU\n",
    "X_FS_none = np.delete(data, selectedOTU_index, axis=1)\n",
    "NG_noselected = metric.Neg_GINI(X_FS_none,y)\n",
    "print(NG_noselected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lasso = data[:,xlabel_lasso]\n",
    "print(X_lasso.shape)\n",
    "X_lasso_none = np.delete(data, xlabel_lasso, axis=1)\n",
    "print(X_lasso_none.shape)\n",
    "Ng1 = metric.Neg_GINI(X_lasso,y)\n",
    "Ng2 = metric.Neg_GINI(X_lasso_none,y)\n",
    "ng_lasso=[Ng1,Ng2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NG_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_lasso[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare lasso and SelectMicro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([NG_selected, ng_lasso[0]], tick_labels=['SelectMicro', 'Lasso'])\n",
    "plt.title(f'NG results of the selected OTU vs. non-selected OTUs')\n",
    "plt.ylabel('NG')\n",
    "plt.grid(axis='y')\n",
    "#print(len(NG_selected[i, :]))\n",
    "# Adjust layout\n",
    "plt.tight_layout()  # Adjusts the subplots to fit into the figure area.\n",
    "plt.show()  # Show all plots at once\n",
    "# the median of Lasso is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the selected and non select by our method\n",
    "\n",
    "plt.boxplot([NG_selected, NG_noselected], tick_labels=['SelectMicro', 'Not selected'])\n",
    "plt.title(f'NG results of the selected OTU vs. non selected OTUs by our method')\n",
    "plt.ylabel('NG')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the selected and non select by lasso\n",
    "\n",
    "plt.boxplot([ng_lasso[0], ng_lasso[1]], tick_labels=['Lasso', 'Not selected'])\n",
    "plt.title(f'NG results of the selected OTU vs. non-selected OTUs by Lasso')\n",
    "plt.ylabel('NG')\n",
    "plt.grid(axis='y')\n",
    "# Adjust layout\n",
    "plt.tight_layout()  # Adjusts the subplots to fit into the figure area.\n",
    "plt.show()  # Show all plots at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import LeaveOneOut, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you already have your data (X: features, y: response)\n",
    "X = X_FS  # Features (numpy array or pandas DataFrame)\n",
    "y = targetLabel  # Target variable (binary or multiclass labels)\n",
    "\n",
    "# Initialize the SVM model (e.g., with an RBF kernel)\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True)  # probability=True for ROC AUC\n",
    "\n",
    "# Set up Leave-One-Out Cross-Validation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# List to store results\n",
    "accuracies = []\n",
    "y_actual = []\n",
    "y_predict = []\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    # Split into training and test data\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Train the SVM model\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the class labels\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "    y_actual.append(y_test)\n",
    "    y_predict.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the mean accuracy and AUC\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Average Accuracy: {metric.accuracy(y_actual,y_predict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM model (e.g., with an RBF kernel)\n",
    "svm_model = SVC(kernel='linear', C=1.0, gamma='scale', probability=True)  # probability=True for ROC AUC\n",
    "\n",
    "# Set up Leave-One-Out Cross-Validation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# List to store results\n",
    "accuracies = []\n",
    "y_actual = []\n",
    "y_predict = []\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    # Split into training and test data\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Train the SVM model\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the class labels\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "    y_actual.append(y_test)\n",
    "    y_predict.append(y_pred)\n",
    "\n",
    "# Calculate and print the mean accuracy and AUC\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Average Accuracy: {metric.accuracy(y_actual,y_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM model (e.g., with an RBF kernel)\n",
    "svm_model = svm.SVC(kernel='linear', probability=True, random_state=777) # probability=True for ROC AUC\n",
    "\n",
    "# Set up Leave-One-Out Cross-Validation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# List to store results\n",
    "accuracies = []\n",
    "y_actual = []\n",
    "y_predict = []\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    # Split into training and test data\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Train the SVM model\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the class labels\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "    y_actual.append(y_test)\n",
    "    y_predict.append(y_pred)\n",
    "\n",
    "# Calculate and print the mean accuracy and AUC\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Average Accuracy: {metric.accuracy(y_actual,y_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM model (e.g., with an RBF kernel)\n",
    "svm_model = svm.SVC(kernel='linear', probability=True, random_state=777) # probability=True for ROC AUC\n",
    "\n",
    "# Set up Leave-One-Out Cross-Validation\n",
    "loo = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "\n",
    "# List to store results\n",
    "accuracies = []\n",
    "y_actual = []\n",
    "y_predict = []\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation\n",
    "for train_idx, test_idx in loo.split(X,y):\n",
    "    # Split into training and test data\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Train the SVM model\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the class labels\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "    y_actual.extend(y_test)\n",
    "    y_predict.extend(y_pred)\n",
    "\n",
    "# Calculate and print the mean accuracy and AUC\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Average Accuracy: {metric.accuracy(y_actual,y_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM model (e.g., with an RBF kernel)\n",
    "svm_model = svm.SVC(kernel='rbf', probability=True, random_state=777) # probability=True for ROC AUC\n",
    "\n",
    "# Set up Leave-One-Out Cross-Validation\n",
    "loo = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "\n",
    "# List to store results\n",
    "accuracies = []\n",
    "y_actual = []\n",
    "y_predict = []\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation\n",
    "for train_idx, test_idx in loo.split(X,y):\n",
    "    # Split into training and test data\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Train the SVM model\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the class labels\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "    y_actual.extend(y_test)\n",
    "    y_predict.extend(y_pred)\n",
    "\n",
    "# Calculate and print the mean accuracy and AUC\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Average Accuracy: {metric.accuracy(y_actual,y_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have your data (X: features, y: response)\n",
    "X = X_lasso_ft  # Features (numpy array or pandas DataFrame)\n",
    "y = targetLabel  # Target variable (binary or multiclass labels)\n",
    "\n",
    "# Initialize the SVM model (e.g., with an RBF kernel)\n",
    "svm_model = svm.SVC(kernel='rbf', probability=True, random_state=777) # probability=True for ROC AUC\n",
    "\n",
    "# Set up Leave-One-Out Cross-Validation\n",
    "loo = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "\n",
    "# List to store results\n",
    "accuracies = []\n",
    "y_actual = []\n",
    "y_predict = []\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation\n",
    "for train_idx, test_idx in loo.split(X,y):\n",
    "    # Split into training and test data\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Train the SVM model\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the class labels\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "    y_actual.extend(y_test)\n",
    "    y_predict.extend(y_pred)\n",
    "\n",
    "# Calculate and print the mean accuracy and AUC\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Average Accuracy: {metric.accuracy(y_actual,y_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have your data (X: features, y: response)\n",
    "X = X_lasso  # Features (numpy array or pandas DataFrame)\n",
    "y = targetLabel  # Target variable (binary or multiclass labels)\n",
    "\n",
    "# Initialize the SVM model (e.g., with an RBF kernel)\n",
    "svm_model = svm.SVC(kernel='rbf', probability=True, random_state=777) # probability=True for ROC AUC\n",
    "\n",
    "# Set up Leave-One-Out Cross-Validation\n",
    "loo = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "\n",
    "# List to store results\n",
    "accuracies = []\n",
    "y_actual = []\n",
    "y_predict = []\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation\n",
    "for train_idx, test_idx in loo.split(X,y):\n",
    "    # Split into training and test data\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Train the SVM model\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the class labels\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "    y_actual.extend(y_test)\n",
    "    y_predict.extend(y_pred)\n",
    "\n",
    "# Calculate and print the mean accuracy and AUC\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Average Accuracy: {metric.accuracy(y_actual,y_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have your data (X: features, y: response)\n",
    "X = X_lasso  # Features (numpy array or pandas DataFrame)\n",
    "y = targetLabel  # Target variable (binary or multiclass labels)\n",
    "\n",
    "# Initialize the SVM model (e.g., with an RBF kernel)\n",
    "svm_model = svm.SVC(kernel='linear', probability=True, random_state=777) # probability=True for ROC AUC\n",
    "\n",
    "# Set up Leave-One-Out Cross-Validation\n",
    "loo = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "\n",
    "# List to store results\n",
    "accuracies = []\n",
    "y_actual = []\n",
    "y_predict = []\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation\n",
    "for train_idx, test_idx in loo.split(X,y):\n",
    "    # Split into training and test data\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Train the SVM model\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the class labels\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "    y_actual.extend(y_test)\n",
    "    y_predict.extend(y_pred)\n",
    "\n",
    "# Calculate and print the mean accuracy and AUC\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Average Accuracy: {metric.accuracy(y_actual,y_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have your data (X: features, y: response)\n",
    "X = X_lasso  # Features (numpy array or pandas DataFrame)\n",
    "y = targetLabel  # Target variable (binary or multiclass labels)\n",
    "\n",
    "# Initialize the SVM model (e.g., with an RBF kernel)\n",
    "svm_model = svm.SVC(kernel='poly', probability=True, random_state=777) # probability=True for ROC AUC\n",
    "\n",
    "# Set up Leave-One-Out Cross-Validation\n",
    "loo = StratifiedKFold(n_splits=5, shuffle=True, random_state=777)\n",
    "\n",
    "# List to store results\n",
    "accuracies = []\n",
    "y_actual = []\n",
    "y_predict = []\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation\n",
    "for train_idx, test_idx in loo.split(X,y):\n",
    "    # Split into training and test data\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Train the SVM model\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the class labels\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "    y_actual.extend(y_test)\n",
    "    y_predict.extend(y_pred)\n",
    "\n",
    "# Calculate and print the mean accuracy and AUC\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Average Accuracy: {metric.accuracy(y_actual,y_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_discriminant_ratio(features, labels):\n",
    "    \"\"\"\n",
    "    Calculate the Fisher's discriminant ratio (F1) for an entire dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - features: A 2D numpy array of feature values (samples x features).\n",
    "    - labels: A 1D numpy array of class labels corresponding to the samples.\n",
    "\n",
    "    Returns:\n",
    "    - F1: Fisher's discriminant ratio for the dataset.\n",
    "    \"\"\"\n",
    "    # Ensure features and labels are numpy arrays\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Get unique classes\n",
    "    classes = np.unique(labels)\n",
    "    if len(classes) != 2:\n",
    "        raise ValueError(\"This implementation only supports two classes.\")\n",
    "\n",
    "    # Calculate class-wise means and overall mean\n",
    "    overall_mean = np.mean(features, axis=0)\n",
    "    class_means = [np.mean(features[labels == c], axis=0) for c in classes]\n",
    "\n",
    "    # Calculate between-class scatter\n",
    "    between_class_scatter = sum(\n",
    "        len(features[labels == c]) * np.outer((class_mean - overall_mean), (class_mean - overall_mean))\n",
    "        for c, class_mean in zip(classes, class_means)\n",
    "    )\n",
    "\n",
    "    # Calculate within-class scatter\n",
    "    within_class_scatter = sum(\n",
    "        sum(np.outer((sample - class_mean), (sample - class_mean)) for sample in features[labels == c])\n",
    "        for c, class_mean in zip(classes, class_means)\n",
    "    )\n",
    "\n",
    "    # Compute Fisher's discriminant ratio\n",
    "    F1 = np.trace(between_class_scatter) / np.trace(within_class_scatter)\n",
    "\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datatype, subset in data_subset.items():\n",
    "    print(f\"f1 of {datatype} = {fisher_discriminant_ratio(subset,targetLabel)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature selection in each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_fulldata = []\n",
    "for i, cl in enumerate(cls):\n",
    "    result_fulldata.append(RunML_continue.cross_fold_validation(data,targetLabel,cl))\n",
    "    print(f\"for {cl}, mean_accuracy = {result_fulldata[i]['mean_accuracy']}, mean_auc = {result_fulldata[i]['mean_auc']}\")\n",
    "    tb_result = metric.metric_tb(result_fulldata[i]['y_true'], result_fulldata[i]['y_pred'])\n",
    "    print(tb_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
