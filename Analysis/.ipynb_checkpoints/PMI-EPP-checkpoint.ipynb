{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the data,in this notebook we are using the PMI data from the paper:\"Environmental predictors impact microbialbased postmortem interval (PMI) estimation models within human decomposition soils\". The preprocessed data includes OTU/phylum/class/order abundance matrices (includes or not include environmental factors).\n",
    "\n",
    "This analysis is mainly for the final project of EPP622, and the analysis is different from the previous file in these ways:\n",
    "\n",
    "1. the data preprocessing is different, previously we \"we only consider OTU/ASVs that make up $\\ge 1\\%$ of the total microbiome community as ``present''\", here we will change the threshold to $0.1\\%$ based on the paper.\n",
    "\n",
    "2. To make it simple, only use 16S data and do not consider environmental data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Code')\n",
    "import loadData \n",
    "import RunML\n",
    "import RunML_continue\n",
    "import FS\n",
    "import metric\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMIdata_path = '../Data/PMI/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No env model\n",
    "16s (OTU/phylum/class/order) - no env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bact_noenv_files = glob.glob(PMIdata_path + 'bact.n.*.noenv.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/PMI/bact.n.otu.noenv.csv',\n",
       " '../Data/PMI/bact.n.order.noenv.csv',\n",
       " '../Data/PMI/bact.n.class.noenv.csv',\n",
       " '../Data/PMI/bact.n.phylum.noenv.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bact_noenv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bact_ITS_noenv_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read each CSV file into a list of dataframes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bact_noenv_df_list \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mread_csv(file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbact_ITS_noenv_files\u001b[49m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bact_ITS_noenv_files' is not defined"
     ]
    }
   ],
   "source": [
    "# Read each CSV file into a list of dataframes\n",
    "bact_noenv_df_list = [pd.read_csv(file) for file in bact_noenv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in bact_noenv_df_list:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bact_noenv_df_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4taxa = []\n",
    "col_names_4taxa = []\n",
    "for df in bact_noenv_df_list:\n",
    "    data = df.drop(df.columns[0], axis=1)\n",
    "    cols_name = data.columns.tolist()\n",
    "    data = data.values\n",
    "    data =FS.relative_abundance(data)\n",
    "    data_4taxa.append(data)\n",
    "    col_names_4taxa.append(cols_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "y = bact_noenv_df_list[3].iloc[:, 0].values \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the threshold\n",
    "y_threshold = 2500\n",
    "\n",
    "# Categorize the series based on the threshold\n",
    "y = np.where(y > y_threshold, 'LONG', 'SHORT')\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(y).count('LONG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(y).count('SHORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. calculate H statistics for OTU/phylum/class/order (both 16s and ITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_4taxa = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for df in data_4taxa:\n",
    "    print(np.shape(df))\n",
    "    weights=FS.OTU_H_Score_fun(df,y,cutOff=0.001)\n",
    "    weights_4taxa.append(weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weight in weights_4taxa:\n",
    "    print(len(weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(weights_4taxa[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedOTU_index_4tax = []\n",
    "eps_4tax = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weight in weights_4taxa:\n",
    "    selectedOTU_index, eps=FS.indice_H_unisig(weight,y)\n",
    "    print(eps)\n",
    "    selectedOTU_index_4tax.append(selectedOTU_index)\n",
    "    eps_4tax.append(eps)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the number of selected features increased for each taxonomic level since we decrease the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Select indices of the features based on H statistics and form the subset based on the selected features.\n",
    "The default p value of the function is 10%, the resulted index is ranked by its H statistics descendingly.\n",
    "\n",
    "Use \"indice_H_unisig\" if there is only one response, use \"indice_H_multisig\" for multiple responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights_4taxa,selectedOTU_index_4tax,col_names_4taxa,eps_4tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_sig_sorted_4taxa = []\n",
    "col_names_sig_sorted_4taxa = []\n",
    "for i in range(len(weights_4taxa)):\n",
    "    weights_sig_sorted = weights_4taxa[i][selectedOTU_index_4tax[i]]\n",
    "    col_names_sig_sorted = [col_names_4taxa[i][j] for j in selectedOTU_index_4tax[i]]\n",
    "    weights_sig_sorted_4taxa.append(weights_sig_sorted)\n",
    "    col_names_sig_sorted_4taxa.append(col_names_sig_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxlabels = ['OTU', 'class', 'order', 'phylum']\n",
    "\n",
    "# Assuming weights_sig_sorted_4taxa contains numeric arrays\n",
    "# Ensure col_names_sig_sorted_4taxa contains the corresponding string labels for each point\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, array in enumerate(weights_sig_sorted_4taxa):\n",
    "    x_values = [taxlabels[i]] * len(array)  # Label each point with its group (e.g., 'OTU', 'class', etc.)\n",
    "    plt.scatter(x_values, array, label=f'{taxlabels[i]}')\n",
    "    \n",
    "    # Annotate each point with its name from col_names_sig_sorted_4taxa[i][j] and its value\n",
    "    for j, z in enumerate(array):\n",
    "        label = col_names_sig_sorted_4taxa[i][j]  # Get the corresponding label for this point\n",
    "        plt.text(taxlabels[i], z, label, ha='center', va='bottom', fontsize=8, color='black')\n",
    "\n",
    "plt.title('Dot Plot of H statistics')\n",
    "plt.xlabel('Taxonomic Rank')\n",
    "plt.ylabel('H statistics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the h statistics and cutoff descendingly\n",
    "#for i in range(len(weights_4taxa)):\n",
    "    #FS.plotWeightedIndex(weights_4taxa[i],threshold=eps_4tax[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4taxa[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model\n",
    "Prepare 4 datasets: full dataset, our selected dataset, Lasso selected  dataset(based on the target variable), randomly selected data (selected the same numer of variables as in our method)\n",
    "\n",
    "Use random forest and SVM as classifier, and will build both models for each response variable.\n",
    "\n",
    "For Lasso, the dataset will be determined by the response variable, so the lasso subset is different for the models for different response variables.\n",
    "\n",
    "For random selection, the  process will repeat iter=30 times to  find the mean accuracy and AUC\n",
    "\n",
    "SMOTE  is used (the data is not balanced, as we can see the performance is really bad especially for SVM model when not using SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter =100\n",
    "cls = [\"RF\",\"SVM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetLabel=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset_4taxa = []\n",
    "X_lasso_4taxa = []\n",
    "xind_lasso_4taxa = []\n",
    "for i, data  in enumerate(data_4taxa):\n",
    "    X_lasso,xind_lasso = RunML_continue.LassoFeatureSelection(data,targetLabel)\n",
    "    X_lasso_4taxa.append(X_lasso_4taxa)\n",
    "    xind_lasso_4taxa.append(xind_lasso)\n",
    "    data_subset = {\"AllFeatures\":data, \n",
    "               \"SelectMicro\": data[:,selectedOTU_index_4tax[i]],\n",
    "               \"Lasso\":X_lasso,\n",
    "               \"Random\":data\n",
    "              }\n",
    "    data_subset_4taxa.append(data_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset  in data_subset_4taxa:\n",
    "    data_subset = dataset\n",
    "    for datatype, subset in data_subset.items():\n",
    "        print(np.shape(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/PMI/subset_bact_4taxa_noenv.pkl', 'wb') as file:\n",
    "    pickle.dump(data_subset_4taxa, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  function will print out the accuracy and AUC for each dataset using each classifier, and also will return the y_actual, y_predict, y_predprob for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_cm = RunML_continue.runClassifier_FScompare(data_subsets= data_subset,y= targetLabel,N=iter,classifiers=cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xind_lasso_4taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plotPresenseRatio(X,label,featurenames,posLabel,posText=\"\",negText=\"\",thresholdPercent=0.90,abundanceCutoff=0.01,entries=15):\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "    presenceCntPos = []\n",
    "    presenceCntNeg = []\n",
    "    \n",
    "    X_relative = FS.relative_abundance(X)\n",
    "    \n",
    "    X_relative = X_relative.T\n",
    "    if abundanceCutoff==0:\n",
    "        flatten_list = list(chain.from_iterable(X_relative))\n",
    "        flatten_list_sorted=sorted(flatten_list)\n",
    "        abundanceCutoff=flatten_list[int(len(flatten_list_sorted)*float(threshold))]\n",
    "\n",
    "    if posText==\"\" or negText==\"\":\n",
    "        posText=posLabel\n",
    "        negText=\"Not \"+posLabel\n",
    "\n",
    "    for k in range(len(X_relative)):## for each OTU\n",
    "        OTUs = X_relative[k]## the samples for this OTU\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        for i in range(len(OTUs)):\n",
    "            if label[i] == posLabel:\n",
    "                if OTUs[i] > abundanceCutoff:# if the value of OTU exceed the abundanceCutoff\n",
    "                    pos += 1\n",
    "            else:\n",
    "                if OTUs[i] > abundanceCutoff:\n",
    "                    neg += 1\n",
    "        presenceCntPos.append(pos)# len= # of samples; each value is the number of OTUs that exceed the abundanceCutoff for Pos/Neg\n",
    "        presenceCntNeg.append(neg)\n",
    "        \n",
    "    all_pos_label_cnt=list(label).count(posLabel)\n",
    "    all_neg_label_cnt=len(label)-all_pos_label_cnt\n",
    "    print(all_pos_label_cnt,all_neg_label_cnt)# these 3  lines can use  value_count\n",
    "    \n",
    "    presenceRatioPos=[float(x)/all_pos_label_cnt for x in presenceCntPos]# each element is for each OTU; shows the ratio of abundanced pos samples over all pos sample \n",
    "    presenceRatioNeg=[float(x)/all_neg_label_cnt for x in presenceCntNeg]\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    y = range(entries)\n",
    "    fig, axes = plt.subplots(ncols=2, sharey=True)\n",
    "    bars_pos = axes[0].barh(y, presenceRatioPos, align='center', color='#ff7f00')\n",
    "    bars_neg =axes[1].barh(y, presenceRatioNeg, align='center', color='#377eb8')\n",
    "    axes[0].set_xlabel(\"Presence Ratio in \"+posText)\n",
    "    axes[1].set_xlabel(\"Presences Ratio \"+negText)\n",
    "\n",
    "    # Annotate each bar in the first subplot\n",
    "    for i, bar in enumerate(bars_pos):\n",
    "        axes[0].text(presenceRatioPos[i], bar.get_y() + bar.get_height() / 2, f'{presenceRatioPos[i]:.2f}', va='center', ha='left')\n",
    "\n",
    "    # Annotate each bar in the second subplot\n",
    "    for i, bar in enumerate(bars_neg):\n",
    "        axes[1].text(presenceRatioNeg[i], bar.get_y() + bar.get_height() / 2, f'{presenceRatioNeg[i]:.2f}', va='center', ha='left')\n",
    "\n",
    "\n",
    "    axes[0].set_xlim(0,1.2)\n",
    "    axes[1].set_xlim(0,1.2)\n",
    "    axes[0].invert_xaxis()# Invert the x-axis of the first subplot\n",
    "\n",
    "    axes[0].set(yticks=y, yticklabels=[])\n",
    "    for yloc, selectedASVs in zip(y, featurenames):\n",
    "        axes[0].annotate(selectedASVs, (0.5, yloc), xycoords=('figure fraction', 'data'),\n",
    "                         ha='center', va='center', fontsize=9)\n",
    "    fig.tight_layout(pad=2.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare the first 15 index by their present ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "entries=15\n",
    "\n",
    "for i, index in enumerate(selectedOTU_index_4tax):\n",
    "    selectedOTU_index_15=index[:entries]\n",
    "    #print(selectedOTU_index_15)\n",
    "    selectedASVs_15=col_names_sig_sorted_4taxa[i][:entries]\n",
    "    print(selectedASVs_15)\n",
    "    X_FS_15=data_4taxa[i][:,selectedOTU_index_15]\n",
    "    #df=pd.DataFrame(data=X_FS_15)\n",
    "    plotPresenseRatio(X_FS_15,targetLabel,selectedASVs_15,posLabel=\"LONG\",posText=\"Long\",negText=\"short\",entries=entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### check the plot results (use phylumn as example)\n",
    "Phy_select_index = selectedOTU_index_4tax[3]\n",
    "Phy_select_index_5 = Phy_select_index[0:5]\n",
    "Phy_select_index_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phy_select_label_5 = [col_names_4taxa[3][i] for i in Phy_select_index_5]\n",
    "print(Phy_select_label_5)\n",
    "print(col_names_sig_sorted_4taxa[3][0:5])\n",
    "print(weights_sig_sorted_4taxa[3][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pyhlum = data_4taxa[3][:,Phy_select_index_5]\n",
    "#X_pyhlum = np.where(X_pyhlum > 0.01, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test \n",
    "data_phy_test=FS.relative_abundance(data_4taxa[3])\n",
    "FS.OTU_H_Score_arr(data_phy_test[:,selectedOTU_index_4tax[3][0:5]],targetLabel,cutOff=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print\n",
    "for i in Phy_select_index_5:\n",
    "    print(\n",
    "    FS.OTU_H_Score(data_4taxa[3][:,i],targetLabel,cutOff=0.01)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights_sig_sorted_4taxa[3])\n",
    "print(weights_4taxa[3][selectedOTU_index_4tax[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Gini Impurity\n",
    "Gini Impurity is the probability of incorrectly classifying a randomly chosen element in the dataset if it were randomly labeled according to the class distribution in the dataset. Itâ€™s calculated as:\n",
    "\n",
    "$G = 1- \\sum_{i=1}^C p_i^2$\n",
    "\n",
    "where C is the number of classes. (which means it can be used to measure for multiple level classification)\n",
    "\n",
    "Here I will use the negative Gini Impurity to measure each OTU, if NG is large (1) which means the OTU only exist in one class, if NG value is small($1/c$) which means the OTU is evenly distributed among  the classes.\n",
    "\n",
    "$NG = \\sum_{i=1}^C p_i^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NG for selected OTU\n",
    "NG_4tax = []\n",
    "for i, data  in enumerate(data_4taxa):\n",
    "    X_FS = data[:,selectedOTU_index_4tax[i]]\n",
    "    X_lasso = data[:,xind_lasso_4taxa[i]]\n",
    "    NG_selected = metric.Neg_GINI(X_FS,y,cutOff=0.01)\n",
    "    NG_Lasso = metric.Neg_GINI(X_lasso,y,cutOff=0.01)\n",
    "    print(NG_selected.shape)\n",
    "    print(NG_Lasso.shape)\n",
    "    NG_4tax.append([NG_selected,NG_Lasso])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the selected and non select by lasso\n",
    "# Number of subplots\n",
    "num_plots = len(data_4taxa)\n",
    "\n",
    "# Create a figure with a grid of subplots\n",
    "plt.figure(figsize=(4, 4 * num_plots))\n",
    "\n",
    "# Loop through each index and create a subplot\n",
    "for i in range(num_plots):\n",
    "    plt.subplot(num_plots, 1, i + 1)  # (nrows, ncols, index)\n",
    "    plt.boxplot([NG_4tax[i][0], NG_4tax[i][1]], tick_labels=['SelectMicro', 'Lasso'])\n",
    "    plt.title(f'NG results of the selected OTU by SelectMicro vs. Lasso - {taxlabels[i]}')\n",
    "    plt.ylabel('NG')\n",
    "    plt.grid(axis='y')\n",
    "# Adjust layout\n",
    "plt.tight_layout()  # Adjusts the subplots to fit into the figure area.\n",
    "plt.show()  # Show all plots at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(col_names_sig_sorted_4taxa):\n",
    "    print(taxlabels[i])\n",
    "    print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
